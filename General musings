General musings:

We start off with separate domains and IP addresses.

Do we treat them as the same or different?

Differences:
a domain name can be used in the host header with a web server to access spacific areas of a server
a domain name has multiple records that can further enumeration
a domain name generally contains one or more IP addresses that it points to

Problem:
Each domain name is linked to an IP address, which is variable to change.
Fix:
Scan IP addresses as a separate entity, with their own folder.


Problem:
Each IP may have multiple webservers, each of which may have different host headers.
Fix:
Treat every subdomain (host header) as a unique webapp / target
The IP address gets added to the IPs folder, and the IP address is also a target
At this point we probably need to go manual, but my process would be the following:
1 - check if unique IP (as in not a CDN, maybe a VPS, normal server or cloud server)
2 - If the IP is unique, attempt to use the host header for all in scope and discovered hosts. If it returns more content, this is now a new webapp/target.
Alternatively:
Don't put too much emphasis on the IP address to Webserver relationship.
Subdomain -> IP
Subdomains have related IP addresses. Sometimes these are CDNs, but even CDNs have origins. There should be an uptime scan which gives the IP address. If the IP address is not a CDN and hasn't been seen before, alert and add the IP address to the IP section of the bugbot.

IP -> Subdomain
For every IP address, perform a reverse DNS lookup. Any hosts found, add to discovered_hosts. Definitely worth noting down where the discovered host was enumerated from, also. Maybe a file called discovered_hosts_origins, with a format like:
example.com:reverse_dns from 1.1.1.1

And if an IP address discovers a webserver, it needs to be added to a relevant dir.


Problem:
Running shell commands and waiting for response appropriately

Fix:
0 - Have an 'executor' script/CLI functionality to handle scans/processes, doing the following:
1 - Adds scan info to the target db in a table called 'live_scans' or something equally appropriate.
1 - Uses a blocking Popen, starttime/scan endtime PID and any errors. 
2 - The followng is a rough idea for the live_scans table:
	ID:                   PRIMARY KEY
    scan_name:            TEXT NOT NULL
    scan_command:         TEXT NOT NULL
    scan_started:         DATE NOT NULL
    scan_completed:		  DATE
    scan_pid:			  TEXT NOT NULL
    scan_status:		  TEXT NOT NULL

3 - scan_status can be:
waiting
running
completed
error
parsed
(more can be added if needed)

4 - Once a scan is complete, it parses the output of the scans within the script with the BB functionality.
5 - Once scan is completed and parsed, runs a bb_alert tool to look over database history and see if there has been any change.
6 - Quite likely worth having slack chats dedicated to progress monitoring - like a room for errors, a room for completed scans, a room for started scans.
7 - Can take an input of multiple tools at once, to run them all in a blocking fashion in a loop to keep processing down.
8 - Possible later feature: run scans as either blocking or async!






